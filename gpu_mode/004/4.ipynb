{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7ce804a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ninja in /opt/conda/lib/python3.11/site-packages (1.11.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Hit:2 http://security.ubuntu.com/ubuntu jammy-security InRelease               \u001b[0m\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease      \u001b[0m       \u001b[0m\u001b[33m\u001b[33m\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease    \u001b[0mm\u001b[33m\n",
      "Hit:4 https://developer.download.nvidia.cn/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
      "Hit:6 https://ppa.launchpadcontent.net/xmake-io/xmake/ubuntu jammy InRelease\n",
      "Reading package lists... Done\u001b[33m\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "84 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "g++-11 is already the newest version (11.4.0-1ubuntu1~22.04).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 84 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "ccache is already the newest version (4.5.1-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 84 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "! pip install ninja\n",
    "! apt update\n",
    "! apt install g++-11 -y\n",
    "# 编译缓存的包，加速编译\n",
    "! apt install ccache -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "845cb480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.cpp_extension\n",
    "import os\n",
    "os.environ['CXX'] = '/usr/lib/ccache/g++-11'\n",
    "os.environ['CC'] = '/usr/lib/ccache/gcc-11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85b440f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /root/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...\n",
      "Creating extension directory /root/.cache/torch_extensions/py311_cu124/test_ext...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py311_cu124/test_ext/build.ninja...\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Building extension module test_ext...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/3] /usr/lib/ccache/g++-11 -MMD -MF main.o.d -DTORCH_EXTENSION_NAME=test_ext -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /opt/conda/lib/python3.11/site-packages/torch/include -isystem /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.11/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.11/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -c /root/.cache/torch_extensions/py311_cu124/test_ext/main.cpp -o main.o \n",
      "[2/3] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda.cuda.o.d -ccbin /usr/lib/ccache/gcc-11 -DTORCH_EXTENSION_NAME=test_ext -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /opt/conda/lib/python3.11/site-packages/torch/include -isystem /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.11/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.11/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' --ptxas-options=-v -std=c++17 -c /root/.cache/torch_extensions/py311_cu124/test_ext/cuda.cu -o cuda.cuda.o \n",
      "ptxas info    : 3 bytes gmem, 24 bytes cmem[4]\n",
      "ptxas info    : Compiling entry function '_Z23rgb_to_grayscale_kernelPhS_i' for 'sm_86'\n",
      "ptxas info    : Function properties for _Z23rgb_to_grayscale_kernelPhS_i\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 14 registers, 372 bytes cmem[0]\n",
      "[3/3] /usr/lib/ccache/g++-11 main.o cuda.cuda.o -shared -L/opt/conda/lib/python3.11/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o test_ext.so\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module test_ext...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.395741900000004 µs\n",
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "         cudaLaunchKernel         8.16%      79.019ms         8.16%      79.019ms       7.902us         10000  \n",
      "    cudaDeviceSynchronize        91.84%     888.894ms        91.84%     888.894ms      88.880us         10001  \n",
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 967.913ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# based on Jeremy's Lecture 3 notebook\n",
    "cuda_begin = r'''\n",
    "#include <torch/extension.h>\n",
    "#include <stdio.h>\n",
    "#include <c10/cuda/CUDAException.h>\n",
    "\n",
    "#define CHECK_CUDA(x) TORCH_CHECK(x.device().is_cuda(), #x \" must be a CUDA tensor\")\n",
    "#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x \" must be contiguous\")\n",
    "#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
    "\n",
    "inline unsigned int cdiv(unsigned int a, unsigned int b) { return (a + b - 1) / b;}\n",
    "'''\n",
    "\n",
    "cuda_src = cuda_begin + r'''\n",
    "__global__ void rgb_to_grayscale_kernel(unsigned char* out, unsigned char* in, int n) {\n",
    "    int i = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "    if (i >= n) return;\n",
    "    out[i] = 0.2989f*in[i] + 0.5870f*in[i+n] + 0.1140f*in[i+2*n];  // fix with f found by Andreas...\n",
    "}\n",
    "\n",
    "torch::Tensor rgb_to_grayscale_out(torch::Tensor output, const torch::Tensor& input) {\n",
    "    CHECK_INPUT(input);\n",
    "    int h = input.size(1);\n",
    "    int w = input.size(2);\n",
    "    TORCH_CHECK((h == output.size(0)) || (w == output.size(1)) || (output.device() == input.device())\n",
    "                || (output.scalar_type() == input.scalar_type()));\n",
    "    int threads = 256;\n",
    "    rgb_to_grayscale_kernel<<<cdiv(w*h,threads), threads>>>(\n",
    "        output.data_ptr<unsigned char>(), input.data_ptr<unsigned char>(), w*h);\n",
    "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
    "    return output;\n",
    "}\n",
    "\n",
    "torch::Tensor rgb_to_grayscale(const torch::Tensor& input) {\n",
    "    CHECK_INPUT(input);\n",
    "    int h = input.size(1);\n",
    "    int w = input.size(2);\n",
    "    auto output = torch::empty({h,w}, input.options());\n",
    "    rgb_to_grayscale_out(output, input);\n",
    "    return output;\n",
    "}\n",
    "'''\n",
    "\n",
    "cpp_src = \"\"\"\n",
    "torch::Tensor rgb_to_grayscale(const torch::Tensor& input);\n",
    "torch::Tensor rgb_to_grayscale_out(torch::Tensor outpuit, const torch::Tensor& input);\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "os.environ['CXX'] = '/usr/lib/ccache/g++-11'\n",
    "os.environ['CC'] = '/usr/lib/ccache/gcc-11'\n",
    "\n",
    "module = torch.utils.cpp_extension.load_inline(\n",
    "    \"test_ext\", cpp_src, cuda_src,\n",
    "    functions=['rgb_to_grayscale', 'rgb_to_grayscale_out'], extra_cuda_cflags=['--ptxas-options=-v'], verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "n = 2048\n",
    "t = torch.randint(0, 256, (3, n, n), dtype=torch.uint8, device=\"cuda\")\n",
    "out = module.rgb_to_grayscale(t); torch.cuda.synchronize()\n",
    "\n",
    "import time\n",
    "t0 = time.perf_counter_ns()\n",
    "for i in range(10_000):\n",
    "    module.rgb_to_grayscale_out(out, t)\n",
    "torch.cuda.synchronize()\n",
    "t1 = time.perf_counter_ns()\n",
    "\n",
    "print((t1-t0) / 10_000 / 1_000, \"µs\")\n",
    "\n",
    "\n",
    "with torch.profiler.profile() as prof:\n",
    "    for i in range(10_000):\n",
    "        module.rgb_to_grayscale_out(out, t)\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "print(prof.key_averages().table())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
